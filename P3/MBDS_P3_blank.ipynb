{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Master's in Health Data Science (MHEDAS)***\n",
        "\n",
        "***Medical Imaging***\n",
        "\n",
        "Professor: Roser Sala Llonch\n",
        "\n",
        "Year 2025-2026\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UpepnaZ0_Z2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# P3. Functional MRI\n",
        "\n",
        "In sthis practical session, we will see different types of functional MRI data and how to analyse them"
      ],
      "metadata": {
        "id": "FH5tK1YF_--A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install nilearn\n",
        "try:\n",
        "    import nilearn\n",
        "except ImportError:\n",
        "    # if not, install it using pip\n",
        "    !pip install nilearn"
      ],
      "metadata": {
        "id": "Z13SxLoRJDnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. The Haxby dataset\n",
        "A study of visual object category identification. It has been widely used in cognitive neuroscience and for brain decoding.\n",
        "The original paper can be found [HERE](https://www.science.org/doi/10.1126/science.1063736)\n",
        "\n"
      ],
      "metadata": {
        "id": "mSklhnmXBKnI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.1. Show stimuli\n",
        "Visualize the set of stimuli used in the task. This is not related to the fMRI data, but it's a good visualization practice."
      ],
      "metadata": {
        "id": "3MrM01mgIMN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nilearn import datasets\n",
        "from nilearn.plotting import show\n",
        "\n",
        "haxby_dataset = datasets.fetch_haxby(subjects=[], fetch_stimuli=True)\n",
        "stimulus_information = haxby_dataset.stimuli\n",
        "\n",
        "for stim_type in stimulus_information:\n",
        "    # skip control images, there are too many\n",
        "    if stim_type != 'controls':\n",
        "\n",
        "        file_names = stimulus_information[stim_type]\n",
        "\n",
        "        fig, axes = plt.subplots(6, 8)\n",
        "        fig.suptitle(stim_type)\n",
        "\n",
        "        for img_path, ax in zip(file_names, axes.ravel()):\n",
        "            ax.imshow(plt.imread(img_path), cmap=plt.cm.gray)\n",
        "\n",
        "        for ax in axes.ravel():\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "show()"
      ],
      "metadata": {
        "id": "Yoe5BWIeI6jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1.1.** Take a look at the paper and explain with your words how are these images used in the context of fMRI"
      ],
      "metadata": {
        "id": "MMUeee4pKEIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*PLACE YOUR ANSWER HERE*"
      ],
      "metadata": {
        "id": "j4g6rvciKVct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.2. Fetch the dataset\n"
      ],
      "metadata": {
        "id": "YqmTqnioKxXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dowload the dataset from nilearn:"
      ],
      "metadata": {
        "id": "XvvX8vQoLtVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # always good to have numpy and pandas in your environment\n",
        "import pandas as pd\n",
        "from nilearn import datasets\n",
        "\n",
        "# fetch the data (by default, 2nd subject will be fetched, check the documentation if you want to change the subject)\n",
        "haxby_dataset = datasets.fetch_haxby()"
      ],
      "metadata": {
        "id": "XWiL7X1qK89o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1.2.1** Examine the data that you've just downloaded. Try to identify the different elements in the dataset (don't worry, just make a guess)"
      ],
      "metadata": {
        "id": "fp-J-QgUL7LK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# place your code (if you need any) here\n"
      ],
      "metadata": {
        "id": "HyfaxYlFMR-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*PLACE YOUR ANSWER HERE*"
      ],
      "metadata": {
        "id": "7suesbzAIHaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the behavioral data (information about how the subject performed the task):"
      ],
      "metadata": {
        "id": "9PdBykoLLu6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load target information as string and give a numerical identifier to each\n",
        "behavioral = pd.read_csv(haxby_dataset.session_target[0], sep=' ')\n",
        "conditions = behavioral['labels'].values\n",
        "\n",
        "# Record these as an array of sessions\n",
        "sessions = behavioral['chunks'].values\n",
        "unique_sessions = behavioral['chunks'].unique()\n",
        "\n",
        "# fMRI data: a unique file for each session\n",
        "func_filename = haxby_dataset.func[0]"
      ],
      "metadata": {
        "id": "b_uEqsQTM7A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1.2.2** Examine what you've loaded."
      ],
      "metadata": {
        "id": "cOJluBX5N4Gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PUT YOUR CODE (IF NEEDED)"
      ],
      "metadata": {
        "id": "ltrh8wYRIQPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*PLACE YOUR ANSWER HERE*"
      ],
      "metadata": {
        "id": "Ie5kjzoPIM0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the session data, we'll create an *event structure* for each session."
      ],
      "metadata": {
        "id": "ujzOacxqOBDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TR = 2.5 # we need to indicate the Time of Repetition (TR) manually\n",
        "events = {}\n",
        "# events will take  the form of a dictionary of Dataframes, one per session\n",
        "for session in unique_sessions:\n",
        "    # get the condition label per session\n",
        "    conditions_session = conditions[sessions == session]\n",
        "    # get the number of scans per session, then the corresponding\n",
        "    # vector of frame times\n",
        "    n_scans = len(conditions_session)\n",
        "    frame_times = TR * np.arange(n_scans)\n",
        "    # each event last the full TR\n",
        "    duration = TR * np.ones(n_scans)\n",
        "    # Define the events object\n",
        "    events_ = pd.DataFrame(\n",
        "        {'onset': frame_times, 'trial_type': conditions_session, 'duration': duration})\n",
        "    # remove the rest condition and insert into the dictionary\n",
        "    events[session] = events_[events_.trial_type != 'rest']"
      ],
      "metadata": {
        "id": "-xc2zbixOX-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1.2.3** Take a look at the new DataFrame. The events can be visualized using the 'plot_event' function.\n",
        "\n"
      ],
      "metadata": {
        "id": "_Rwdc3ZiPbbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "events"
      ],
      "metadata": {
        "id": "yE6g6-KBQ8XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nilearn.plotting import plot_event\n",
        "\n",
        "# PLACE YOUR CODE HERE (tip: look at the help of the function)"
      ],
      "metadata": {
        "id": "Kex3QByjPjRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3. Define the GLM model and run the analyses.\n",
        "\n",
        "We'll use tools from nilearn to generate the statistical model.\n",
        "\n",
        "REMEMBER: A first level model is the statistical comparison between the different *conditions* (or blocks) from a *single subject*.\n",
        "\n",
        "You can find more information [HERE](https://nilearn.github.io/stable/glm/index.html)"
      ],
      "metadata": {
        "id": "x7qCuxiESG26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z_maps = []\n",
        "conditions_label = []\n",
        "session_label = []\n",
        "\n",
        "# Instantiate the glm\n",
        "from nilearn.glm.first_level import FirstLevelModel\n",
        "glm = FirstLevelModel(t_r=TR,\n",
        "                      mask_img=haxby_dataset.mask,\n",
        "                      high_pass=.008,\n",
        "                      smoothing_fwhm=4,\n",
        "                      memory='nilearn_cache')\n",
        "\n"
      ],
      "metadata": {
        "id": "UyEw_EY_UIgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running the GLM massively, let's try to understand it with one example:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0XzgrQbzc3gQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "events[session].trial_type.unique()\n",
        "from nilearn.image import index_img\n",
        "fmri_session = index_img(func_filename, sessions ==0)\n",
        "glm.fit(fmri_session, events = events[0])"
      ],
      "metadata": {
        "id": "Em_SBSUWdeUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nilearn.plotting import plot_design_matrix\n",
        "design_matrix = glm.design_matrices_[0]\n",
        "plot_design_matrix(design_matrix)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GpGDfSHzeHzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, run the GLM on **each** session from the *events* dataframe.  "
      ],
      "metadata": {
        "id": "M5bgh-pqVC5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now run the GLM on each session\n",
        "events[session].trial_type.unique()\n",
        "from nilearn.image import index_img\n",
        "for session in unique_sessions:\n",
        "    # grab the fmri data for that particular session\n",
        "    fmri_session = index_img(func_filename, sessions == session)\n",
        "\n",
        "    # fit the glm\n",
        "    glm.fit(fmri_session, events=events[session])\n",
        "\n",
        "    # set up contrasts: one per condition\n",
        "    conditions = events[session].trial_type.unique()\n",
        "    for condition_ in conditions:\n",
        "        z_maps.append(glm.compute_contrast(condition_))\n",
        "        conditions_label.append(condition_)\n",
        "        session_label.append(session)"
      ],
      "metadata": {
        "id": "wrDnAyb-VBlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1.3.1**: Explain what do you interpret from the figure. You can plot other sessions to see the differences."
      ],
      "metadata": {
        "id": "S-7Sw95_UgLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.4. Understanding the **contrasts** and generate a report of the results."
      ],
      "metadata": {
        "id": "RqjEcB7RfQLI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll use a specific function that generates a summary report of the results of the First Level analysis."
      ],
      "metadata": {
        "id": "gOGGOoh7fyJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nilearn.image import mean_img\n",
        "from nilearn.reporting import make_glm_report\n",
        "mean_img_ = mean_img(func_filename)\n",
        "report = make_glm_report(glm,\n",
        "                         contrasts=conditions,\n",
        "                         bg_img=mean_img_,\n",
        "                         )\n",
        "\n",
        "report  # This report can be viewed in a notebook"
      ],
      "metadata": {
        "id": "fE31V5mMfujT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.5. A decoding pipeline"
      ],
      "metadata": {
        "id": "mKisBx99EyN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part uses Machine Learning to implement a decoder.  "
      ],
      "metadata": {
        "id": "77cXC6pqFRhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nilearn.decoding import Decoder\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "decoder = Decoder(estimator='svc', mask=haxby_dataset.mask, standardize=False,\n",
        "                  screening_percentile=5, cv=LeaveOneGroupOut())\n",
        "decoder.fit(z_maps, conditions_label, groups=session_label)\n",
        "\n",
        "# Return the corresponding mean prediction accuracy compared to chance\n",
        "\n",
        "classification_accuracy = np.mean(list(decoder.cv_scores_.values()))\n",
        "chance_level = 1. / len(np.unique(conditions))\n",
        "print('Classification accuracy: {:.4f} / Chance level: {}'.format(\n",
        "    classification_accuracy, chance_level))"
      ],
      "metadata": {
        "id": "2g-oRPf0E6zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1.5.1**: examine the inputs and outputs of the decoder and interpret the results."
      ],
      "metadata": {
        "id": "rrBlqiyeFbVy"
      }
    }
  ]
}